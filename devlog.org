#+PROPERTY: COOKIE_DATA recursive
#+STARTUP: overview

* design

** frontend (packages/app)
- http://localhost:7891
- proxies ~/api~ and ~/sync~ to the backend in development
- uses Dexie for local storage with sync plugin
- custom sync replication implementation using PeerJS through the signalling server

** backend (packages/server)
- http://localhost:7890
- serves ~/dist~ if the directory is present (see ~dist~ script)
- serves ~/api~ for RSS caching proxy
  - file-based routing under the api directory
- serves ~/sync~ which is a ~peerjs~ signalling server

** sync
- each client keeps the full data set
- dexie sync and observable let us stream change sets
- we can publish the "latest" to all peers
- on first pull, if not the first client, we can request a dump out of band

*** rss feed data
- do we want to backup feed data?
  - conceptually, this should be refetchable
  - but feeds go away, and some will only show recent stories
    - so yes, we'll need this
  - but server side, we can dedupe
    - content-addressed server-side cache?

- server side does RSS pulling
  - can feeds be marked private, such that they won't be pulled through the proxy?
  - but then we require everything to be fetchable via cors
    - client configured proxy settings?

*** peer connection
- on startup, check for current realm-id and key pair
- if not present, ask to login or start new
  - if login, run through the [[* pairing]] process
  - if start new, run through the [[* registration]] process
- use keypair to authenticate to server
  - response includes list of active peers to connect
- clients negotiate sync from there
- an identity is a keypair and a realm

- realm is uuid
  - realm on the server is the socket connection for peer discovery
    - keeps a list of verified public keys
    - and manages the /current/ ~public-key->peer ids~ mapping
  - realm on the client side is first piece of info required for sync
    - when connecting to the signalling server, you present a realm, and a signed public key
    - server accepts/rejects based on signature and current verified keys

- a new keypair can create a realm

- a new keypair can double sign an invitation
  - invite = ~{ realm:, nonce:, not_before:, not_after:, authorizer: }~, signed with verified key
  - exchanging an invite = ~{ invite: }~, signed with my key

- on startup
  - start stand-alone (no syncing required, usually the case on first-run)
    - generate a keypair
    - want server backup?
      - sign a "setup" message with new keypair and send to the server
      - server responds with a new realm, that this keypair is already verified for
    - move along
  - exchange invite to sync to other devices
    - generate a keypair
    - sign the exchange message with the invite and send to the server
      - server verifies the invite
      - adds the new public key to the peer list and publishes downstream
    - move along

***** standalone
in this mode, there is no syncing. this is the most likely first-time run option.

- generate a keypair on startup, so we have a stable fingerprint in the future
- done

***** pairing
in this mode, there is syncing to a named realm, but not necessarily server resources consumed
we don't need an email, since the server is just doing signalling and peer management

- generate an invite from an existing verified peer
  - ~{ realm:, not_before:, not_after:, inviter: peer.public_key }~
  - sign that invitation from the existing verified peer

- standalone -> paired
  - get the invitation somehow (QR code?)
  - sign an invite exchange with the standalone's public key
  - send to server
    - server verifies the invite
    - adds the new public key to the peer list and publishes downstream

***** server backup
in this mode, there is syncing to a named realm by email.

goal of server backup mode is that we can go from email->fully working client with latest data without having to have any clients left around that could participate in the sync.

- generate a keypair on startup
- sign a registration message sent to the server
  - send a verification email
    - if email/realm already exists, this is authorization
    - if not, it's email validation
  - server starts a realm and associates the public key
  - server acts as a peer for the realm, and stores private data

- since dexie is publishing change sets, we should be able to just store deltas
- but we'll need to store _all_ deltas, unless we're materializing on the server side too
  - should we use an indexdb shim so we can import/export from the server for clean start?
  - how much materialization does the server need?

* ai instructions
- when writing to the devlog, add tags to your entries specifying ~:ai:~ and what tool did it.
- false starts and prototypes are in ~./devlog/~

* notes and decision record [1/11]
** architecture design (may 28-29)                               :ai:claude:

details notes are in [[./devlog/may-29.org]]
key decisions and system design:

*** sync model
- device-specific records for playback state/queues to avoid conflicts
- content-addressed server cache with deduplication
- dual-JWT invitation flow for secure realm joining

*** data structures
- tag-based filtering system instead of rigid hierarchies
- regex patterns for episode title parsing and organization
- service worker caching with background download support

*** core schemas
**** client (dexie)
- Channel/ChannelEntry for RSS feeds and episodes
- PlayRecord/QueueItem scoped by deviceId
- FilterView for virtual feed organization

**** server (drizzle)
- ContentStore for deduplicated content by hash
- Realm/PeerConnection for sync authorization
- HttpCache with health tracking and TTL

*** push sync strategy
- revision-based sync (just send revision ranges in push notifications)
- background fetch API for large downloads where supported
- graceful degradation to reactive caching

*** research todos                                                :ai:claude:

**** sync and data management
***** DONE identity and signature management
***** TODO dexie sync capabilities vs rxdb for multi-device sync implementation
***** TODO webrtc p2p sync implementation patterns and reliability
***** TODO conflict resolution strategies for device-specific data in distributed sync
***** TODO content-addressed deduplication algorithms for rss/podcast content
**** client-side storage and caching
***** TODO opfs storage limits and cleanup strategies for client-side caching
***** TODO practical background fetch api limits and edge cases for podcast downloads
**** automation and intelligence
***** TODO llm-based regex generation for episode title parsing automation
***** TODO push notification subscription management and realm authentication
**** platform and browser capabilities
***** TODO browser audio api capabilities for podcast-specific features (speed, silence skip)
***** TODO progressive web app installation and platform-specific behaviors

# Local Variables:
# org-hierarchical-todo-statistics: nil
# org-checkbox-hierarchical-statistics: nil
# End:
